{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End to end Deep Learning project using Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\GOPALAKRISHNAN\\Downloads\\python\\AIML\\machine_learning\\0026_RNN\\0002_Simple_RNN_Implementation\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000,), Training labels shape: (25000,)\n",
      "Testing data shape: (25000,), Testing labels shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "## Load the imdb dataset\n",
    "\n",
    "max_features=10000 ##vocabulary size\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape: {X_train.shape}, Testing labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review (as integers):[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "Sample label: 0\n"
     ]
    }
   ],
   "source": [
    "## Inspect a sample review and its label\n",
    "sample_review=X_train[1]\n",
    "sample_label=y_train[1]\n",
    "\n",
    "print(f\"Sample review (as integers):{sample_review}\")\n",
    "print(f'Sample label: {sample_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_len=500\n",
    "\n",
    "X_train=sequence.pad_sequences(X_train,maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\GOPALAKRISHNAN\\Downloads\\python\\AIML\\machine_learning\\0026_RNN\\0002_Simple_RNN_Implementation\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Simple RNN\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,128,input_length=max_len)) ## Embedding Layers\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1313025 (5.01 MB)\n",
      "Trainable params: 1313025 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build((None, max_len))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\GOPALAKRISHNAN\\Downloads\\python\\AIML\\machine_learning\\0026_RNN\\0002_Simple_RNN_Implementation\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.EarlyStopping at 0x2525354b690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an instance of EarlyStoppping Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n",
    "earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\GOPALAKRISHNAN\\Downloads\\python\\AIML\\machine_learning\\0026_RNN\\0002_Simple_RNN_Implementation\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\GOPALAKRISHNAN\\Downloads\\python\\AIML\\machine_learning\\0026_RNN\\0002_Simple_RNN_Implementation\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "625/625 [==============================] - 32s 50ms/step - loss: 12396.9717 - accuracy: 0.5889 - val_loss: 0.6050 - val_accuracy: 0.6592\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.4141 - accuracy: 0.8164 - val_loss: 0.3887 - val_accuracy: 0.8356\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.2404 - accuracy: 0.9028 - val_loss: 0.3679 - val_accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.1878 - accuracy: 0.9269 - val_loss: 0.3902 - val_accuracy: 0.8350\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.1268 - accuracy: 0.9552 - val_loss: 0.4210 - val_accuracy: 0.8498\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.0858 - accuracy: 0.9704 - val_loss: 0.4713 - val_accuracy: 0.8468\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.5185 - val_accuracy: 0.8456\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.5840 - val_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "## Train the model with early sstopping\n",
    "history=model.fit(\n",
    "    X_train,y_train,epochs=10,batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model file\n",
    "model.save('imdb_simple_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the IMDB dataset word index\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Helper Functions\n",
    "# Function to decode reviews\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    encoded_review = [word_index.get(word, 2) + 3 for word in words]\n",
    "    padded_review = sequence.pad_sequences([encoded_review], maxlen=500)\n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Helper Functions\n",
    "# Function to decode reviews\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    encoded_review = [word_index.get(word, 2) + 3 for word in words]\n",
    "    padded_review = sequence.pad_sequences([encoded_review], maxlen=500)\n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction  function\n",
    "\n",
    "def predict_sentiment(review):\n",
    "    \n",
    "    preprocessed_input=preprocess_text(review)\n",
    "\n",
    "    prediction=model.predict(preprocessed_input)\n",
    "\n",
    "    sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'\n",
    "    \n",
    "    return sentiment, prediction[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "Review: This movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Sentiment: Positive\n",
      "Prediction Score: 0.6694377064704895\n"
     ]
    }
   ],
   "source": [
    "# Step 4: User Input and Prediction\n",
    "# Example review for prediction\n",
    "example_review = \"This movie was fantastic! The acting was great and the plot was thrilling.\"\n",
    "\n",
    "sentiment,score=predict_sentiment(example_review)\n",
    "\n",
    "print(f'Review: {example_review}')\n",
    "print(f'Sentiment: {sentiment}')\n",
    "print(f'Prediction Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
